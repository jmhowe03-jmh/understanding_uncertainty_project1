{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f420726",
   "metadata": {},
   "source": [
    "# Project 1 (Due Nov 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd9e64",
   "metadata": {},
   "source": [
    "The goal of the first project is to non-parametrically model some phenomenon of interest, and generate sequences of values. There are six options below:\n",
    "\n",
    "- Chordonomicon: 680,000 chord progressions of popular music songs. Create a chord generator, similar to what we did with Bach in class, but for a particular artist or genre. (https://github.com/spyroskantarelis/chordonomicon)\n",
    "- Financial Time series, S&P500 Stocks: There are 500 time series here. Model how individual time series adjust over time, either together or separately. (https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks)\n",
    "- MIT-BIT Arrythmia Database: Arrythmia is an abnormal heart rhythm. This is a classic dataset that a day of ECG time series measurements for 4,000 patients. (https://www.physionet.org/content/mitdb/1.0.0/)\n",
    "- Ukraine conflict monitor: The ACLED Ukraine Conflict Monitor provides near real-time information on the ongoing war in Ukraine, including an interactive map, a curated data file, and weekly situation updates Ukraine Conflict Monitor, maintained by the Armed Conflict Location & Event Data Project, starting in 2022, including battles, explosions/remote violence, violence against civilians, protests, and riots:\n",
    "https://acleddata.com/monitor/ukraine-conflict-monitor\n",
    "- SIPRI Arms Trade: The SIPRI Arms Transfers Database is a comprehensive public resource tracking all international transfers of major conventional arms from 1950 to the present. For each deal, information includes: number ordered, supplier/recipient identities, weapon types, delivery dates, and deal comments. The database can address questions about: who are suppliers and recipients of major weapons, what weapons have been transferred by specific countries, and how supplier-recipient relationships have changed over time.\n",
    "https://www.sipri.org/databases/armstransfers\n",
    "- Environmental Protection Agency data: The EPA, in general, has excellent data on the release of toxic substances, and I also tracked down air quality and asthma. You can put these together to look at how changes in toxic release correlate with air quality and respiratory disease over time:\n",
    "https://www.epa.gov/data\n",
    "https://www.epa.gov/toxics-release-inventory-tri-program/tri-toolbox\n",
    "https://www.cdc.gov/asthma/most_recent_national_asthma_data.htm\n",
    "https://www.earthdata.nasa.gov/topics/atmosphere/air-quality/data-access-tools\n",
    "\n",
    "If you have other data sources that you're interested in, I am willing to consider them, as long as they lend themselves to an interesting analysis.\n",
    "\n",
    "Submit a document or notebook that clearly addresses the following:\n",
    "1. Describe the data clearly -- particularly any missing data that might impact your analysis -- and the provenance of your dataset. Who collected the data and why? (10/100 pts)\n",
    "2. What phenomenon are you modeling? Provide a brief background on the topic, including definitions and details that are relevant to your analysis. Clearly describe its main features, and support those claims with data where appropriate. (10/100 pts)\n",
    "3. Describe your non-parametric model (empirical cumulative distribution functions, kernel density function, local constant least squares regression, Markov transition models). How are you fitting your model to the phenomenon to get realistic properties of the data? What challenges did you have to overcome? (15/100 pts)\n",
    "4. Either use your model to create new sequences (if the model is more generative) or bootstrap a quantity of interest (if the model is more inferential). (15/100 pts)\n",
    "5. Critically evaluate your work in part 4. Do your sequences have the properties of the training data, and if not, why not? Are your estimates credible and reliable, or is there substantial uncertainty in your results? (15/100 pts)\n",
    "6. Write a conclusion that explains the limitations of your analysis and potential for future work on this topic. (10/100 pts)\n",
    "\n",
    "In addition, submit a GitHub repo containing your code and a description of how to obtain the original data from the source. Make sure the code is commented, where appropriate. Include a .gitignore file. We will look at your commit history briefly to determine whether everyone in the group contributed. (10/100 pts)\n",
    "\n",
    "In class, we'll briefly do presentations and criticize each other's work, and participation in your group's presentation and constructively critiquing the other groups' presentations accounts for the remaining 15/100 pts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62de2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4679ee",
   "metadata": {},
   "source": [
    "## DATA DESCRIPTION & PROVENANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696db90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp500_index.csv:       2,517 rows × 2 cols\n",
      "sp500_companies.csv:   502 companies\n",
      "sp500_stocks.csv:      1,891,536 rows\n",
      "\n",
      "DATA PROVENANCE\n",
      "Source: Kaggle - https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks\n",
      "Author: Andrew Mvd\n",
      "Collection: Automated daily pull from Yahoo Finance API\n",
      "Purpose: Public dataset for ML, research, and financial analysis\n",
      "Last updated: ~Nov 2025 (daily updates)\n",
      "\n",
      "MISSING VALUES REPORT\n",
      "S&P500 Index missing: 0 (0%)\n",
      "Companies EBITDA null: 5.78%\n",
      "Stocks Adj Close null: 67.34% ← Critical!\n",
      "\n",
      "IMPACT OF MISSING DATA:\n",
      "- 67.3% missing Adj Close in sp500_stocks.csv → many stocks only have recent data\n",
      "  (e.g., new S&P 500 additions like CRWD, PLTR)\n",
      "- We will ONLY use sp500_index.csv for modeling → complete, clean, 2,517 trading days\n",
      "- This avoids bias from partial stock histories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "index_df = pd.read_csv('data/sp500_index.csv')\n",
    "companies_df = pd.read_csv('data/sp500_companies.csv')\n",
    "stocks_df = pd.read_csv('data/sp500_stocks.csv')\n",
    "\n",
    "print(f\"sp500_index.csv:       {index_df.shape[0]:,} rows × {index_df.shape[1]} cols\")\n",
    "print(f\"sp500_companies.csv:   {companies_df.shape[0]} companies\")\n",
    "print(f\"sp500_stocks.csv:      {stocks_df.shape[0]:,} rows\")\n",
    "\n",
    "# Provenance\n",
    "print(\"\\nDATA PROVENANCE\")\n",
    "print(\"Source: Kaggle - https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks\")\n",
    "print(\"Author: Andrew Mvd\")\n",
    "print(\"Collection: Automated daily pull from Yahoo Finance API\")\n",
    "print(\"Purpose: Public dataset for ML, research, and financial analysis\")\n",
    "print(\"Last updated: ~Nov 2025 (daily updates)\")\n",
    "\n",
    "# Missing data - EXACT MATCH TO YOUR OUTPUT\n",
    "print(\"\\nMISSING VALUES REPORT\")\n",
    "print(f\"S&P500 Index missing: {index_df['S&P500'].isna().sum()} (0%)\")\n",
    "print(f\"Companies EBITDA null: {companies_df['Ebitda'].isna().mean()*100:.2f}%\")\n",
    "print(f\"Stocks Adj Close null: {stocks_df['Adj Close'].isna().mean()*100:.2f}% ← Critical!\")\n",
    "\n",
    "print(\"\"\"\n",
    "IMPACT OF MISSING DATA:\n",
    "- 67.3% missing Adj Close in sp500_stocks.csv → many stocks only have recent data\n",
    "  (e.g., new S&P 500 additions like CRWD, PLTR)\n",
    "- We will ONLY use sp500_index.csv for modeling → complete, clean, 2,517 trading days\n",
    "- This avoids bias from partial stock histories\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS5030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
