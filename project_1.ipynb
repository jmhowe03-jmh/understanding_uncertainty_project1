{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f420726",
   "metadata": {},
   "source": [
    "# Project 1 (Due Nov 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd9e64",
   "metadata": {},
   "source": [
    "The goal of the first project is to non-parametrically model some phenomenon of interest, and generate sequences of values. There are six options below:\n",
    "\n",
    "- Chordonomicon: 680,000 chord progressions of popular music songs. Create a chord generator, similar to what we did with Bach in class, but for a particular artist or genre. (https://github.com/spyroskantarelis/chordonomicon)\n",
    "- Financial Time series, S&P500 Stocks: There are 500 time series here. Model how individual time series adjust over time, either together or separately. (https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks)\n",
    "- MIT-BIT Arrythmia Database: Arrythmia is an abnormal heart rhythm. This is a classic dataset that a day of ECG time series measurements for 4,000 patients. (https://www.physionet.org/content/mitdb/1.0.0/)\n",
    "- Ukraine conflict monitor: The ACLED Ukraine Conflict Monitor provides near real-time information on the ongoing war in Ukraine, including an interactive map, a curated data file, and weekly situation updates Ukraine Conflict Monitor, maintained by the Armed Conflict Location & Event Data Project, starting in 2022, including battles, explosions/remote violence, violence against civilians, protests, and riots:\n",
    "https://acleddata.com/monitor/ukraine-conflict-monitor\n",
    "- SIPRI Arms Trade: The SIPRI Arms Transfers Database is a comprehensive public resource tracking all international transfers of major conventional arms from 1950 to the present. For each deal, information includes: number ordered, supplier/recipient identities, weapon types, delivery dates, and deal comments. The database can address questions about: who are suppliers and recipients of major weapons, what weapons have been transferred by specific countries, and how supplier-recipient relationships have changed over time.\n",
    "https://www.sipri.org/databases/armstransfers\n",
    "- Environmental Protection Agency data: The EPA, in general, has excellent data on the release of toxic substances, and I also tracked down air quality and asthma. You can put these together to look at how changes in toxic release correlate with air quality and respiratory disease over time:\n",
    "https://www.epa.gov/data\n",
    "https://www.epa.gov/toxics-release-inventory-tri-program/tri-toolbox\n",
    "https://www.cdc.gov/asthma/most_recent_national_asthma_data.htm\n",
    "https://www.earthdata.nasa.gov/topics/atmosphere/air-quality/data-access-tools\n",
    "\n",
    "If you have other data sources that you're interested in, I am willing to consider them, as long as they lend themselves to an interesting analysis.\n",
    "\n",
    "Submit a document or notebook that clearly addresses the following:\n",
    "1. Describe the data clearly -- particularly any missing data that might impact your analysis -- and the provenance of your dataset. Who collected the data and why? (10/100 pts)\n",
    "2. What phenomenon are you modeling? Provide a brief background on the topic, including definitions and details that are relevant to your analysis. Clearly describe its main features, and support those claims with data where appropriate. (10/100 pts)\n",
    "3. Describe your non-parametric model (empirical cumulative distribution functions, kernel density function, local constant least squares regression, Markov transition models). How are you fitting your model to the phenomenon to get realistic properties of the data? What challenges did you have to overcome? (15/100 pts)\n",
    "4. Either use your model to create new sequences (if the model is more generative) or bootstrap a quantity of interest (if the model is more inferential). (15/100 pts)\n",
    "5. Critically evaluate your work in part 4. Do your sequences have the properties of the training data, and if not, why not? Are your estimates credible and reliable, or is there substantial uncertainty in your results? (15/100 pts)\n",
    "6. Write a conclusion that explains the limitations of your analysis and potential for future work on this topic. (10/100 pts)\n",
    "\n",
    "In addition, submit a GitHub repo containing your code and a description of how to obtain the original data from the source. Make sure the code is commented, where appropriate. Include a .gitignore file. We will look at your commit history briefly to determine whether everyone in the group contributed. (10/100 pts)\n",
    "\n",
    "In class, we'll briefly do presentations and criticize each other's work, and participation in your group's presentation and constructively critiquing the other groups' presentations accounts for the remaining 15/100 pts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4679ee",
   "metadata": {},
   "source": [
    "## Data Description and Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696db90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== data/sp500_companies.csv ===\n",
      "Shape: (502, 16)\n",
      "Missing values:\n",
      "                   Missing Count  Percent Missing\n",
      "Ebitda                        29            5.777\n",
      "State                         20            3.984\n",
      "Fulltimeemployees              9            1.793\n",
      "Revenuegrowth                  3            0.598\n",
      "--------------------------------------------------\n",
      "\n",
      "=== data/sp500_index.csv ===\n",
      "Shape: (2517, 2)\n",
      "Date range: 2014-12-22 00:00:00 to 2024-12-20 00:00:00\n",
      "No missing values in any column.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== data/sp500_stocks.csv ===\n",
      "Shape: (1891536, 8)\n",
      "Date range: 2010-01-04 00:00:00 to 2024-12-20 00:00:00\n",
      "Missing values:\n",
      "           Missing Count  Percent Missing\n",
      "Adj Close         100475            5.312\n",
      "Close             100475            5.312\n",
      "High              100475            5.312\n",
      "Low               100475            5.312\n",
      "Open              100475            5.312\n",
      "Volume            100475            5.312\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load files\n",
    "companies = pd.read_csv('data/sp500_companies.csv')\n",
    "index_df  = pd.read_csv('data/sp500_index.csv')\n",
    "stocks    = pd.read_csv('data/sp500_stocks.csv')\n",
    "\n",
    "\n",
    "# Convert dates\n",
    "index_df['Date'] = pd.to_datetime(index_df['Date'], errors='coerce')\n",
    "stocks['Date']   = pd.to_datetime(stocks['Date'],   errors='coerce')\n",
    "\n",
    "\n",
    "def missing_report(df, name):\n",
    "   print(f\"\\n=== {name} ===\")\n",
    "   print(f\"Shape: {df.shape}\")\n",
    "   if 'Date' in df.columns:\n",
    "       print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "   missing = df.isnull().sum()\n",
    "   percent = 100 * missing / len(df)\n",
    "   report = pd.DataFrame({'Missing Count': missing, 'Percent Missing': percent})\n",
    "   report = report[report['Missing Count'] > 0].sort_values('Percent Missing', ascending=False)\n",
    "   if not report.empty:\n",
    "       print(\"Missing values:\")\n",
    "       print(report.round(3))\n",
    "   else:\n",
    "       print(\"No missing values in any column.\")\n",
    "   print(\"-\" * 50)\n",
    "\n",
    "\n",
    "missing_report(companies, \"data/sp500_companies.csv\")\n",
    "missing_report(index_df,  \"data/sp500_index.csv\")\n",
    "missing_report(stocks,    \"data/sp500_stocks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f41ebf",
   "metadata": {},
   "source": [
    "### Data Description and Missing Value Summary\n",
    "\n",
    "This project uses three related datasets describing the S&P 500 index and its constituent companies.\n",
    "\n",
    "(a) sp500_companies.csv\n",
    "\n",
    "- Shape: (502 × 16)  \n",
    "- Description: Contains company-level metadata and financial indicators for S&P 500 constituents.  \n",
    "- Key columns: Exchange, Symbol, Shortname, Sector, Industry, Currentprice, Marketcap, Ebitda, Revenuegrowth, Fulltimeemployees, etc.  \n",
    "\n",
    "Missing Data:\n",
    "\n",
    "| Column             | Missing Count | Percent Missing |\n",
    "|--------------------|---------------|-----------------|\n",
    "| Ebitda             | 29            | 5.78%           |\n",
    "| State              | 20            | 3.98%           |\n",
    "| Fulltimeemployees  | 9             | 1.79%           |\n",
    "| Revenuegrowth      | 3             | 0.60%           |\n",
    "\n",
    "Interpretation: \n",
    "Most missing data appear in financial fields (Ebitda, Revenuegrowth) and location-related fields (State).  \n",
    "These gaps likely stem from incomplete corporate disclosures or companies headquartered outside the U.S.  \n",
    "The dataset otherwise has complete coverage of essential identification and classification fields such as Symbol and Sector.\n",
    "\n",
    "(b) sp500_index.csv\n",
    "\n",
    "- Shape: (2,517 × 2)  \n",
    "- Date range: 2014-12-22 → 2024-12-20  \n",
    "- Columns: Date, S&P500 (daily closing level).  \n",
    "- Missing data: None detected.  \n",
    "\n",
    "Interpretation:  \n",
    "The index file is fully complete, covering approximately ten years of daily observations.  \n",
    "This makes it an ideal foundation for modeling index-level returns or volatility.\n",
    "\n",
    "(c) sp500_stocks.csv\n",
    "\n",
    "- Shape: (1,891,536 × 8)  \n",
    "- Date range: 2010-01-04 → 2024-12-20  \n",
    "- Columns: Date, Symbol, Open, High, Low, Close, Adj Close, Volume.  \n",
    "\n",
    "Missing Data:\n",
    "\n",
    "| Column     | Missing Count | Percent Missing |\n",
    "|-------------|----------------|-----------------|\n",
    "| Adj Close   | 100,475        | 5.31%           |\n",
    "| Close       | 100,475        | 5.31%           |\n",
    "| High        | 100,475        | 5.31%           |\n",
    "| Low         | 100,475        | 5.31%           |\n",
    "| Open        | 100,475        | 5.31%           |\n",
    "| Volume      | 100,475        | 5.31%           |\n",
    "\n",
    "Interpretation:  \n",
    "We will investigate the missing values further in the next code block.\n",
    "\n",
    "### Data Provenance\n",
    "\n",
    "The datasets used in this project originate from the Kaggle dataset  \n",
    "**[“S&P 500 Stocks”](https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks)**.  \n",
    "This dataset aggregates information about S&P 500 companies, their historical prices, and the overall index level.\n",
    "\n",
    "Source Details:\n",
    "- Platform: Kaggle  \n",
    "- Dataset Owner: Larxel (dataset maintainer)  \n",
    "- Collection Methodology: Data collected from the Federal Reserve Economic Data (FRED) and the Yahoo Finance (yfinance) API.  \n",
    "- License: CC0: Public Domain \n",
    "- Update Frequency: Daily (last updated approximately one year ago)  \n",
    "- Temporal Coverage: 2010–2024   \n",
    "- Dataset Version Used: v1022 (the most recent reliable version)  \n",
    "\n",
    "> Note:\n",
    "> The latest version of the dataset (v1023) contains approximately 67% missing values, rendering it unsuitable for analysis.  \n",
    "> Therefore, this project uses version 1022, which provides complete and consistent coverage for the S&P 500 index and its constituent stock data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8627ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing rows: 100,475\n",
      "Tickers with missing data: 72\n",
      "\n",
      "--- Top 15 tickers with MOST missing days ---\n",
      "Symbol\n",
      "AMTM    3705\n",
      "SW      3650\n",
      "GEV     3583\n",
      "SOLV    3583\n",
      "VLTO    3461\n",
      "KVUE    3356\n",
      "GEHC    3261\n",
      "CEG     3032\n",
      "ABNB    2754\n",
      "PLTR    2704\n",
      "OTIS    2569\n",
      "CARR    2569\n",
      "CRWD    2375\n",
      "CTVA    2363\n",
      "UBER    2353\n"
     ]
    }
   ],
   "source": [
    "price_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "full_missing = stocks[price_cols].isna().all(axis=1)\n",
    "\n",
    "\n",
    "# 1. Count missing rows per ticker\n",
    "missing_per_ticker = (\n",
    "   full_missing.groupby(stocks['Symbol'])\n",
    "   .sum()\n",
    "   .astype(int)\n",
    "   .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Show results\n",
    "print(f\"Total missing rows: {full_missing.sum():,}\")\n",
    "print(f\"Tickers with missing data: {missing_per_ticker[missing_per_ticker > 0].shape[0]}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Top 15 tickers with MOST missing days ---\")\n",
    "print(missing_per_ticker.head(15).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea82fd",
   "metadata": {},
   "source": [
    "### Missing values in `sp500_stocks.csv'\n",
    "\n",
    "We examined which specific tickers had missing data in the sp500_stocks.csv dataset.  \n",
    "Out of approximately 1.89 million rows (covering 2010–2024), there are 100,475 rows with missing values across *all* price and volume columns — about 5.31% of the dataset.  \n",
    "\n",
    "Only 72 tickers are affected, primarily recent S&P 500 additions such as AMTM (3,705 missing days), SW, GEV, and SOLV (2024 spin-offs), followed by VLTO, KVUE, GEHC, CEG, ABNB, PLTR, OTIS, CARR, CRWD, CTVA, and UBER (added between 2019–2023).  \n",
    "\n",
    "These gaps correspond to periods before each company joined the index, not data errors.  \n",
    "They occur because the dataset spans the entire 2010–2024 period, even though many of these firms entered the S&P 500 mid-period.  \n",
    "The remaining ~430 tickers have complete trading histories.  \n",
    "\n",
    "This pattern of missingness is structural and expected, reflecting real-world index composition changes rather than issues with data collection.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS5030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
